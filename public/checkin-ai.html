<!DOCTYPE html>
<html lang="vi">

<head>
  <meta charset="UTF-8" />
  <title>üì∏ Check-in AI</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="/socket.io/socket.io.js"></script>
  <script src="/face-api.min.js"></script>
  <style>
    body {
      background: #000;
      color: #fff;
      font-family: Arial;
      text-align: center;
      margin: 0;
    }

    input,
    button,
    select {
      padding: 10px;
      margin: 6px;
      border-radius: 8px;
      border: none;
      font-size: 16px;
    }

    button {
      background: #0a7;
      color: #fff;
    }

    #videoBox {
      width: 90%;
      max-width: 360px;
      margin: 10px auto;
      border: 4px solid #0f0;
      border-radius: 16px;
      box-shadow: 0 0 20px #0f0;
    }

    video,
    canvas {
      width: 100%;
      border-radius: 12px;
    }

    #status {
      margin-top: 8px;
      font-size: 14px;
      color: #0f0;
    }
  </style>
</head>

<body>
  <h1>üì∏ CHECK-IN AI</h1>
  <input id="name" placeholder="H·ªç t√™n" />
  <input id="phone" placeholder="SƒêT" />
  <br>
  <button id="startBtn">üé• B·∫≠t camera</button><br>
  <select id="cameraSelect"></select>
  <div id="videoBox">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas" style="display:none;"></canvas>
  </div>
  <button id="checkinBtn" disabled>‚úÖ Check-in</button>
  <div id="status">Ch∆∞a b·∫≠t camera</div>
  <script>
    const socket = io();
    let buffetCount = 0;
    let stream = null;
    let currentDeviceId = null;

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const cameraSelect = document.getElementById("cameraSelect");
    const status = document.getElementById("status");
    const checkinBtn = document.getElementById("checkinBtn");

    async function loadModels() {
      try {
        await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
        await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
        status.textContent = "üìö Models loaded OK";
      } catch (err) {
        status.textContent = "‚ùå L·ªói load models: " + err.message;
      }
    }
    loadModels();

    async function loadCameras() {
      try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        const cams = devices.filter(d => d.kind === "videoinput");
        cameraSelect.innerHTML = '<option value="">Ch·ªçn camera</option>';
        cams.forEach((c, i) => {
          const option = document.createElement("option");
          option.value = c.deviceId;
          option.text = c.label || `Camera ${i + 1}`;
          cameraSelect.appendChild(option);
        });
        if (cams.length === 0) {
          status.textContent = "‚ùå Kh√¥ng t√¨m th·∫•y camera. Vui l√≤ng ki·ªÉm tra quy·ªÅn camera.";
        }
      } catch (err) {
        status.textContent = "‚ùå L·ªói load camera list: " + err.message;
      }
    }

    async function startCamera(deviceId) {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: {
            deviceId: deviceId ? { exact: deviceId } : undefined,
            facingMode: "user" // ∆∞u ti√™n camera tr∆∞·ªõc
          }
        });
        video.srcObject = stream;
        checkinBtn.disabled = false;
        status.textContent = "üì∏ ƒê∆∞a m·∫∑t v√†o khung v√† b·∫•m Check-in";
        loadCameras(); // Load l·∫°i list sau khi xin quy·ªÅn
      } catch (err) {
        status.textContent = "‚ùå Kh√¥ng th·ªÉ m·ªü camera: " + err.message;
        if (err.name === "NotAllowedError") {
          status.textContent += " ‚Üí Vui l√≤ng cho ph√©p quy·ªÅn camera trong c√†i ƒë·∫∑t tr√¨nh duy·ªát.";
        } else if (err.name === "NotFoundError") {
          status.textContent += " ‚Üí Kh√¥ng t√¨m th·∫•y camera.";
        }
        checkinBtn.disabled = true;
      }
    }

    // S·ª± ki·ªán n√∫t b·∫≠t camera
    document.getElementById("startBtn").onclick = async () => {
      await loadCameras();
      if (currentDeviceId) {
        await startCamera(currentDeviceId);
      } else if (cameraSelect.options.length > 1) {
        await startCamera(cameraSelect.options[1].value); // Ch·ªçn camera ƒë·∫ßu ti√™n
      } else {
        // M·ªü camera m·∫∑c ƒë·ªãnh n·∫øu ch∆∞a ch·ªçn
        await startCamera();
      }
    };

    // Thay ƒë·ªïi camera
    cameraSelect.onchange = async () => {
      currentDeviceId = cameraSelect.value;
      if (currentDeviceId) await startCamera(currentDeviceId);
    };

    // Check-in
    checkinBtn.onclick = async () => {
      const name = document.getElementById("name").value.trim();
      const phone = document.getElementById("phone").value.trim();
      if (!name || !phone) {
        alert("Nh·∫≠p ƒë·ªß h·ªç t√™n v√† SƒêT");
        return;
      }

      try {
        const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptor();

        if (!detections) {
          status.textContent = "‚ùå Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t";
          return;
        }

        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);

        socket.emit("checkin", {
          name,
          phone,
          image: canvas.toDataURL("image/jpeg"),
          descriptor: Array.from(detections.descriptor)
        });

        status.textContent = "‚úÖ Check-in th√†nh c√¥ng!";
      } catch (err) {
        status.textContent = "‚ùå L·ªói check-in: " + err.message;
      }
    };

    // Socket events
    socket.on("connect", () => {
      console.log("üì∫ Big Buffet connected:", socket.id);
    });

    socket.on("action_screen", data => {
      if (data.action !== "buffet") return;

      buffetCount++;
      document.getElementById("count").textContent = buffetCount;

      document.getElementById("photo").src = data.image;
      document.getElementById("name").textContent = data.name || "Kh√°ch Buffet";
      document.getElementById("phone").textContent = data.phone
        ? "SƒêT: ***" + data.phone.slice(-3)
        : "";

      document.getElementById("box").classList.add("show");
    });
  </script>
</body>

</html>